"""
Simple Indian Language Translator
Uses smart hybrid language detection
"""

import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from lang_indicators import SmartLanguageDetector

class SimpleIndicTranslator:
    def __init__(self):
        print("ğŸš€ Initializing Simple Indic Translator...")
        
        # Initialize smart language detector
        self.detector = SmartLanguageDetector()
        
        # Initialize IndicTrans2 model
        print("ğŸ“¥ Loading IndicTrans2 model...")
        self.model_name = "ai4bharat/indictrans2-indic-en-1B"
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_name, 
            trust_remote_code=True
        )
        self.model = AutoModelForSeq2SeqLM.from_pretrained(
            self.model_name,
            trust_remote_code=True,
            torch_dtype=torch.float16,
            device_map="auto"
        )
        print("âœ… IndicTrans2 model loaded successfully!")
    
    def translate(self, text, target_lang="eng_Latn"):
        """Simple translation with smart language detection"""
        if not text or not text.strip():
            return "No text provided", "unknown", {}
        
        # Detect source language using smart detector
        print(f"ğŸ” Detecting language for text: {text[:50]}...")
        src_lang = self.detector.detect_language(text)
        detection_info = self.detector.get_detection_method(text)
        
        print(f"âœ… Language detected: {src_lang}")
        print(f"   Detection method: {detection_info.get('method', 'unknown')}")
        print(f"   Confidence: {detection_info.get('confidence', 'unknown')}")
        
        # Format input for IndicTrans2
        formatted_text = f"{src_lang} {target_lang} {text}"
        
        try:
            # Check if text is too long and truncate if necessary
            max_length = 400  # Leave some room for special tokens
            if len(text) > max_length:
                text = text[:max_length]
                print(f"   Text truncated to {max_length} characters")
                formatted_text = f"{src_lang} {target_lang} {text}"
            
            # Tokenize and translate
            inputs = self.tokenizer(
                [formatted_text], 
                return_tensors="pt", 
                truncation=True, 
                max_length=512,
                padding=True
            )
            
            # Check if inputs are valid
            if not inputs or not inputs.get('input_ids') is not None:
                raise ValueError("Invalid tokenizer output")
                
            # Move inputs to the model's device
            inputs = {k: v.to(self.model.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_length=512,
                    num_beams=4,
                    early_stopping=True,
                    no_repeat_ngram_size=2
                )
            
            # Decode result
            translation = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            print(f"âœ… Translation successful: {translation[:100]}...")
            
            return translation, src_lang, detection_info
            
        except Exception as e:
            print(f"âŒ Translation error: {str(e)}")
            
            # Try with Marathi as fallback for Devanagari text
            if self.detector.is_devanagari_script(text) and src_lang != "mar_Deva":
                try:
                    print("ğŸ”„ Trying Marathi as fallback for Devanagari text")
                    formatted_text = f"mar_Deva {target_lang} {text}"
                    
                    # Tokenize and translate
                    inputs = self.tokenizer(
                        [formatted_text], 
                        return_tensors="pt", 
                        truncation=True, 
                        max_length=512,
                        padding=True
                    )
                    
                    # Check if inputs are valid
                    if not inputs or not inputs.get('input_ids') is not None:
                        raise ValueError("Invalid tokenizer output in fallback")
                        
                    # Move inputs to the model's device
                    inputs = {k: v.to(self.model.device) for k, v in inputs.items()}
                    
                    with torch.no_grad():
                        outputs = self.model.generate(
                            **inputs,
                            max_length=512,
                            num_beams=4,
                            early_stopping=True,
                            no_repeat_ngram_size=2
                        )
                    
                    # Decode result
                    translation = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
                    
                    print(f"âœ… Fallback translation successful: {translation[:100]}...")
                    return translation, "mar_Deva", {"method": "fallback", "confidence": "medium"}
                    
                except Exception as fallback_error:
                    print(f"âŒ Fallback translation also failed: {fallback_error}")
            
            # If all translation attempts fail, return a basic translation or the original text
            return f"Translation error: {str(e)}", src_lang, detection_info

def test_smart_detection():
    """Test the smart hybrid detection"""
    translator = SimpleIndicTranslator()
    
    print("\n" + "="*70)
    print("ğŸ§ª SMART HYBRID DETECTION TEST")
    print("="*70)
    
    test_cases = [
        # Devanagari languages (custom detection)
        ("Hindi", "à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚? à¤•à¥à¤¯à¤¾ à¤†à¤ª à¤–à¤¾à¤¨à¤¾ à¤–à¤¾ à¤šà¥à¤•à¥‡ à¤¹à¥ˆà¤‚?"),
        ("Marathi", "à¤¨à¤®à¤¸à¥à¤•à¤¾à¤°, à¤¤à¥à¤®à¥à¤¹à¥€ à¤•à¤¸à¥‡ à¤†à¤¹à¤¾à¤¤? à¤¤à¥à¤®à¤šà¥‡ à¤•à¤¾à¤® à¤à¤¾à¤²à¥‡ à¤•à¤¾?"),
        ("Gujarati", "àª¨àª®àª¸à«àª¤à«‡, àª¤àª®à«‡ àª•à«‡àª® àª›à«‹? àª¤àª®à«‡ àª–à«‹àª°àª¾àª• àª–àª¾àª§à«‹ àª›à«‡?"),
        
        # Non-Devanagari languages (langdetect)
        ("Bengali", "à¦¨à¦®à¦¸à§à¦•à¦¾à¦°, à¦†à¦ªà¦¨à¦¿ à¦•à§‡à¦®à¦¨ à¦†à¦›à§‡à¦¨? à¦†à¦ªà¦¨à¦¿ à¦•à¦¿ à¦–à¦¾à¦¬à¦¾à¦° à¦–à§‡à¦¯à¦¼à§‡à¦›à§‡à¦¨?"),
        ("Tamil", "à®µà®£à®•à¯à®•à®®à¯, à®¨à¯€à®™à¯à®•à®³à¯ à®à®ªà¯à®ªà®Ÿà®¿ à®‡à®°à¯à®•à¯à®•à®¿à®±à¯€à®°à¯à®•à®³à¯?"),
        ("Telugu", "à°¨à°®à°¸à±à°•à°¾à°°à°‚, à°®à±€à°°à± à°à°²à°¾ à°‰à°¨à±à°¨à°¾à°°à±?"),
        ("Malayalam", "à´¨à´®à´¸àµà´•à´¾à´°à´‚, à´¨à´¿à´™àµà´™àµ¾ à´à´™àµà´™à´¨àµ†à´¯à´¿à´°à´¿à´•àµà´•àµà´¨àµà´¨àµ?"),
        ("Kannada", "à²¨à²®à²¸à³à²•à²¾à²°, à²¨à³€à²µà³ à²¹à³‡à²—à²¿à²¦à³à²¦à³€à²°à²¿?"),
        ("Punjabi", "à¨¸à¨¤ à¨¸à©à¨°à©€ à¨…à¨•à¨¾à¨², à¨¤à©à¨¸à©€à¨‚ à¨•à¨¿à¨µà©‡à¨‚ à¨¹à©‹?"),
        
        # English
        ("English", "Hello, how are you? Have you eaten?"),
        
        # Mixed language
        ("Mixed", "Hello, how are you? à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚?"),
    ]
    
    print(f"\nğŸ“Š Testing {len(test_cases)} samples with hybrid detection...\n")
    
    for title, text in test_cases:
        print(f"\nğŸ”¤ {title}:")
        print(f"   Input: {text}")
        
        translation, detected_lang, detection_info = translator.translate(text)
        
        print(f"   ğŸ” Method: {detection_info['method']}")
        print(f"   ğŸŒ Detected: {detected_lang}")
        print(f"   ğŸ“ Translation: {translation}")
        print("   " + "-" * 50)

def main():
    """Main application"""
    translator = SimpleIndicTranslator()
    
    print("\n" + "="*70)
    print("ğŸ¤– SIMPLE INDIAN LANGUAGE TRANSLATOR")
    print("="*70)
    print("Smart Features:")
    print("  â€¢ langdetect for Bengali, Tamil, Telugu, etc.")
    print("  â€¢ Custom detection for Hindi/Marathi/Gujarati")
    print("  â€¢ Fast and accurate")
    
    # Interactive mode
    print("\nğŸ’¬ INTERACTIVE MODE")
    print("Type any Indian language text to translate!")
    
    while True:
        user_input = input("\nğŸ“ Enter text: ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'q']:
            print("ğŸ¯ Thank you for using the translator!")
            break
        elif user_input.lower() == 'test':
            test_smart_detection()
            continue
        elif not user_input:
            continue
        
        # Translate with smart detection
        translation, detected_lang, detection_info = translator.translate(user_input)
        
        print(f"ğŸ” Detection: {detection_info['method']}")
        print(f"ğŸŒ Language: {detected_lang}")
        print(f"ğŸ“ Translation: {translation}")

if __name__ == "__main__":
    main()
